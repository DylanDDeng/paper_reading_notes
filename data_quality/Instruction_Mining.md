# Instruction Mining: High-Quality Instruction Data Selection for Large Language Models  


## 前言 

本篇论文是来自CMU和Lehigh大学的三位作者，关于给大语言模型选择高质量的指令数据的文章。原论文地址：[https://arxiv.org/abs/2307.06290](https://arxiv.org/abs/2307.06290) 

作者指出尽管指令微调能够大幅度地提升大模型理解人类指令的能力，但是获取高质量的指令现阶段比较常用的手段还是要经过人工的处理。所以，作者在这里提出了一种叫做指令挖掘(Instruct Mining)的方法,这种方法是基于一种线性的规则，能够在不需要人工的情况下选择高质量的指令数据。 

通过这种方法选择的数据去做模型微调后，发现模型在42.5%的情况下表现更好。 
> *Comprehensive results show that INSTRUCTMINING can significantly improve finetuning performance. The model fine-tuned on filtered data performs better in 42.5% of the cases.* 

## 设计与实验 

首先，我们要理解一个概念，什么叫做指令质量？ 


通常来说，一个模型掌握的大部分知识都是在预训练阶段学习的；在微调阶段，指令数据会教模型怎么去更好地遵守人类的意图，跟人类进行互动，所以，指令数据的质量可以看作一种引导语言模型以特定方式生成响应的能力。简单来说就是，指令数据的质量决定了模型响应人类指令的能力，指令数据的质量高，那模型响应人类指令的能力就会好。 
> *the quality of these instruction-following data could be viewed as its ability to efficiently steer language models in learning to generate responses in a particular manner.* 

基于此，作者提出了一个评估指令质量评估的推测，如下： 

给定一个指令数据集，记作$`D`$，基于这个指令数据集，微调了一个模型，记作$`\tilde{M}`$。那么这个指令数据集$`D`$的质量是可以通过微调模型$`\tilde{M}`$在评估集$`D_{eval}`$上的推理损失进行估计的。

为了确保模型推理的损失能够提供对数据质量评估提供一个有效的度量，评估集$`D_{eval}`$需要由无偏的，高质量的指令数据样例组成。 

上述的文字表达，如果用数学符号来表示，则为如下： 
$$`
Q_{D|M,S} \propto -L(\tilde{M}, D_{eval})
`
$$ 

在这个式子里，$`D_{eval}`$ 指的是高质量的无偏评估集，$`D`$是指令数据集，$M$是需要微调的基线模型，$S$是训练的参数设置集合，$`\propto`$表示正比例。

根据这个式子，我们可以利用微调后的模型$`\tilde{M}`$在评估集$`D_{eval}`$的损失来评估指令数据集的质量。但是，这么做，效率是很低的，因为还要涉及到微调模型这一步，所以作者在这里引入了一些自然语言的指标，并使用这些指标来预测推理损失，从而评估指令数据的质量。

论文中给出的自然语言指标如下所示：
![Alt text](image.png)  

这些指标组成一个集合$`I`$表示，{$`I={I_{i},i \in N^{*}}`$}；给定指令数据集$`D`$,我们就可以计算对应的指标的值，记作$`I(D)={I_{i}(D), i \in N^{*}}`$,这样，我们就可以认为存在一个函数$`F`$使得之前提到过的模型推理损失$`L(\tilde{M},D_{eval})`$可以用$`F(I(D))`$来近似。

用数据公式来表达，作者也在原论文中给出，则如下所示：
![Alt text](image-1.png)  

通过这个式子，我们可以看到指令数据的质量的负数与微调模型的对数推理损失成正相关的关系，而损失又可以通过一个函数$`F`$去逼近。

作者假设存在多变量线性函数$`I_{i}, i \in {1,...,n}`$使得与对数损失成比例关系，则上面那个式子就可以重新写成如下：

$$`  
\begin{aligned}

logL(\tilde{M},D_{eval}) &\propto L_{0} + F{(D)}\\
&\propto L_{0} + \beta_{0} + \beta_{1}I_{1}(D) + ...+\beta_{n}I_{n}(D) + \epsilon  

\end{aligned} 
`
$$ 

$`\beta_{0}`$是常数，$`\beta_{i}, i\in N^{*}`$是线性系数，$`\epsilon`$是随机噪音。 

这里我们稍微总结一下，作者等于说把评判一个指令数据集已经转化成了一个线性回归的问题，把一些自然语言指标作为输入$`x_{i}`$,对数损失作为输出$`y_{i}`$,以此来评估指令数据的质量。 

到这里作者关于指令数据的质量的推测就解释完了，下面来看一下作者具体是怎么设计实验的。 

作者进行了两类实验了来检验自然语言指标和数据集质量的关系，一种是多变量相关性实验还有一种是单变量相关性实验。两种实验的主要区别在于数据采样的策略不同。 

对于多变量实验流程，作者给出了下图示例进行解释
![Alt text](image-2.png)  

整个多变量实验流程分为如下几步： 
* 首先选择一些候选的数据集
* 对它们进行采样和融合，组成质量不同水平的数据集。
* 对每一个数据集，都微调一个语言模型，然后在共享的评估集上进行评估；并且计算不同数据集中，每一个自然语言指标的值。 
* 最终，进行线性回归分析，预估线性规则参数。 

对于单变量的实验，作者不是像之前那样随机采样，而是进行了细颗粒度的采样,子数据集的采样基于自然语言指标的值。对于一个指定的指标$`I_j`$, 采用一系列相同大小的子数据集，这些子数据集具有细颗粒指标值。 

这里我们拿作者原论文中举的一个例子来说明